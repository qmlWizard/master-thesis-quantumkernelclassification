{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pennylane as qml\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerFaultData(method = 'pca'):\n",
    "\n",
    "\tif method == 'pca':\n",
    "\t\tpowerData = pd.read_csv('/Users/digvijay/Developer/MasterThesis/master-thesis-quantumkernelclassification/Code/DR_data/pca3.csv')\n",
    "\t\t\n",
    "\t\tX = []\n",
    "\t\tY = []\n",
    "\n",
    "\t\tX = powerData[['pc1', 'pc2', 'pc3']]\n",
    "\t\tY = powerData[['fault']]\n",
    "\t\tY = np.asarray(Y).astype(int)\n",
    "\n",
    "\t\txTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.95, shuffle=True, random_state=42)\n",
    "\t\txTrain = preprocessing.normalize(xTrain)\n",
    "\t\txTest = preprocessing.normalize(xTest)\n",
    "\n",
    "\t\treturn xTrain, yTrain\n",
    "\t\n",
    "\tif method == 'fda':\n",
    "\t\tpowerData = pd.read_csv('/Users/digvijay/Developer/MasterThesis/master-thesis-quantumkernelclassification/Code/DR_data/lda3.csv')\n",
    "\t\t\n",
    "\t\tX = []\n",
    "\t\tY = []\n",
    "\n",
    "\t\tX = powerData[['LD1', 'LD2', 'LD3']]\n",
    "\t\tY = powerData[['fault']]\n",
    "\t\tY = np.asarray(Y).astype(int)\n",
    "\n",
    "\t\txTrain, xTest, yTrain, yTest = train_test_split(X, Y, test_size = 0.95, shuffle=True, random_state=42)\n",
    "\t\txTrain = preprocessing.normalize(xTrain)\n",
    "\t\txTest = preprocessing.normalize(xTest)\n",
    "\n",
    "\t\treturn xTrain, yTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = powerFaultData('fda')\n",
    "\n",
    "print(\"Data: \", X[0])\n",
    "print(\"Label: \", Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_alignment(\n",
    "    X,\n",
    "    Y,\n",
    "    kernel,\n",
    "    assume_normalized_kernel=False,\n",
    "    rescale_class_labels=True,\n",
    "):\n",
    "    \"\"\"Kernel-target alignment between kernel and labels.\"\"\"\n",
    "\n",
    "    K = qml.kernels.square_kernel_matrix(\n",
    "        X,\n",
    "        kernel,\n",
    "        assume_normalized_kernel=assume_normalized_kernel,\n",
    "    )\n",
    "\n",
    "    if rescale_class_labels:\n",
    "        nplus = np.count_nonzero(np.array(Y) == 1)\n",
    "        nminus = len(Y) - nplus\n",
    "        _Y = np.array([y / nplus if y == 1 else y / nminus for y in Y])\n",
    "    else:\n",
    "        _Y = np.array(Y)\n",
    "\n",
    "    T = np.outer(_Y, _Y)\n",
    "    inner_product = np.sum(K * T)\n",
    "    norm = np.sqrt(np.sum(K * K) * np.sum(T * T))\n",
    "    inner_product = inner_product / norm\n",
    "\n",
    "    return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=3, shots=None)\n",
    "wires = dev.wires.tolist()\n",
    "\n",
    "def layer(x, params, wires, i0=0, inc=1):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    i = i0\n",
    "    for j, wire in enumerate(wires):\n",
    "        qml.Hadamard(wires=[wire])\n",
    "        qml.RZ(x[i % len(x)], wires=[wire])\n",
    "        #qml.RZ(x[i], wires=[wire])\n",
    "        i += inc\n",
    "        qml.RY(params[0, j], wires=[wire])\n",
    "\n",
    "    qml.broadcast(unitary=qml.CRZ, pattern=\"ring\", wires=wires, parameters=params[1])\n",
    "    \n",
    "def ansatz(x, params, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    for j, layer_params in enumerate(params):\n",
    "        layer(x, layer_params, wires, i0=j * len(wires))\n",
    "        \n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "def random_params(num_wires, num_layers):\n",
    "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
    "    return np.random.uniform(0, 2 * np.pi, (num_layers, 2, num_wires), requires_grad=True)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2, params):\n",
    "    ansatz(x1, params, wires=wires)\n",
    "    adjoint_ansatz(x2, params, wires=wires)\n",
    "    return qml.probs(wires=wires)\n",
    "\n",
    "def kernel(x1, x2, params):\n",
    "    return kernel_circuit(x1, x2, params)[0]\n",
    "\n",
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params = random_params(num_wires=3, num_layers=6)\n",
    "print(init_params)\n",
    "kernel_value = kernel(X[0], X[1], init_params)\n",
    "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")\n",
    "print('---------------------------------------------------------------------------------------------')\n",
    "print('Quantum Circuit: ')\n",
    "drawer = qml.draw(kernel_circuit)\n",
    "print(drawer(X[0], X[1], init_params))\n",
    "print('---------------------------------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel Alignment with Gradient Descent\")\n",
    "\n",
    "params = init_params\n",
    "opt = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "for i in range(500):\n",
    "    # Choose subset of datapoints to compute the KTA on.\n",
    "    \n",
    "    subset = np.random.choice(list(range(len(X))), 4)\n",
    "\n",
    "    #print(type(subset))\n",
    "    #print(type(Y))\n",
    "    \n",
    "    # Define the cost function for optimization\n",
    "    cost = lambda _params: -target_alignment(\n",
    "        X[subset],\n",
    "        Y[subset],\n",
    "        lambda x1, x2: kernel(x1, x2, _params),\n",
    "        assume_normalized_kernel=True,\n",
    "    )\n",
    "    \n",
    "    # Optimization step\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "    # Report the alignment on the full dataset every 50 steps.\n",
    "    if (i + 1) % 10 == 0:\n",
    "        current_alignment = target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "        print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")\n",
    "\n",
    "\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y)\n",
    "\n",
    "accuracy_trained = accuracy(svm_trained, X, Y)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncertinitySamplingSubset(X, svm_trained, subSize):\n",
    "\t\n",
    "\tprobabilities = svm_trained.predict_proba(X)\n",
    "\tentropy = -np.sum(probabilities * np.log(probabilities), axis=1)\n",
    "\tselected_indices = np.argsort(entropy)[:subSize]\n",
    "\n",
    "\treturn selected_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Kernel Alignment with Gradient Descent with Active Learning\")\n",
    "\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix, probability=True)\n",
    "svm_trained.fit(X, Y)\n",
    "\n",
    "accuracy_trained = accuracy(svm_trained, X, Y)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")\n",
    "\n",
    "params = init_params\n",
    "opt = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "for i in range(500):\n",
    "    # Choose subset of datapoints to compute the KTA on.\n",
    "    \n",
    "    #subset = np.random.choice(list(range(len(X))), 4) \n",
    "    trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "    trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "    svm_trained = SVC(kernel=trained_kernel_matrix, probability=True).fit(X, Y)\n",
    "    \n",
    "    subset = uncertinitySamplingSubset(X, svm_trained=svm_trained, subSize=4)\n",
    "\n",
    "    #print(type(subset))\n",
    "    #print(type(Y))\n",
    "    \n",
    "    # Define the cost function for optimization\n",
    "    cost = lambda _params: -target_alignment(\n",
    "        X[subset],\n",
    "        Y[subset],\n",
    "        lambda x1, x2: kernel(x1, x2, _params),\n",
    "        assume_normalized_kernel=True,\n",
    "    )\n",
    "    \n",
    "    # Optimization step\n",
    "    params = opt.step(cost, params)\n",
    "\n",
    "    # Report the alignment on the full dataset every 50 steps.\n",
    "    if (i + 1) % 10 == 0:\n",
    "        current_alignment = target_alignment(\n",
    "            X,\n",
    "            Y,\n",
    "            lambda x1, x2: kernel(x1, x2, params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "        print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")\n",
    "\n",
    "trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "svm_trained = SVC(kernel=trained_kernel_matrix).fit(X, Y)\n",
    "\n",
    "accuracy_trained = accuracy(svm_trained, X, Y)\n",
    "print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
